{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set-up (run this only once)\n",
    "# installing all necessary modules \n",
    "# using the Conda package manager and an environment file\n",
    "!conda env create --name machinelearning --file environment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages (data handling, sklearn for carrying out supervised classification, visualisation)\n",
    "!source activate machinelearning\n",
    "\n",
    "# import necessary modules\n",
    "import numpy as np         \n",
    "import pandas as pd           # for dataframe manipulation\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split  # to split the dataset into one train & one test sets\n",
    "from sklearn.metrics import confusion_matrix        # to calculate metrics on the trained classifier and see how well it perfoms on the test dataset\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score # to calculate the accuracy of the trained classifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt # for plots\n",
    "import seaborn as sns;           # for plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now installed and loaded the modules necessary for our analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation of the datasets\n",
    "The breast cancer dataset (`breast-cancer-wisconsin.csv`) has 11 columns and 699 rows.\n",
    "\n",
    "Column descriptions: \n",
    "\n",
    "\n",
    "\n",
    "| nÂ° | attribute   |Domain|\n",
    "|------|------|------|\n",
    "|   1  | Sample number|id number |\n",
    "|   2  | Clump thickness|1-10|\n",
    "|   3  | Uniformity of Cell Size|1-10  |\n",
    "|   4  | Uniformity of Cell Shape|1-10  |\n",
    "|   5  | Marginal Adhesion |1-10  |\n",
    "|   6  | Single Epithelial Cell Size|1-10  |\n",
    "|   7  | Bare Nuclei   |1-10  |\n",
    "|   8  | Bland Chromatin |1-10  |\n",
    "|   9  | Normal Nucleoli |1-10  |\n",
    "|   10  | Mitoses |1-10  |\n",
    "|   11  | Class|2,4  |\n",
    "\n",
    "\n",
    "For the cancer class (column \"Class\"):\n",
    "- 2: benign cancer\n",
    "- 4: malignant cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv(filepath_or_buffer=\"breast-cancer-wisconsin.csv\",header=None)\n",
    "\n",
    "# rename columns\n",
    "col_names = [\"CodeNumber\", \"ClumpThickness\", \"UniformityCellSize\", \"UniformityCellShape\", \"MarginalAdhesion\",\n",
    "               \"SingleEpithelialCellSize\", \"BareNuclei\",\"BlandChromatin\", \"NormalNucleoli\", \"Mitoses\",\n",
    "               \"CancerType\"]\n",
    "df.columns= col_names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the BareNuclei column (since it contains missing values coded as \"?\")\n",
    "del df[\"BareNuclei\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the original data into a train and a test dataset\n",
    "We are now going to use our original dataset to:\n",
    "- train a Random Forest (RF) model\n",
    "- test our RF model on a test dataset.\n",
    "\n",
    "We are going to split our dataset (`breast-cancer-wisconsin`) into a train and a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the label (=y) variable (cancer class)\n",
    "label = df.CancerType\n",
    "\n",
    "# specify the features (=x) variables (measured variables)\n",
    "features = df.iloc[:,1:9]\n",
    "\n",
    "# Split dataset into a random train and test subsets\n",
    "# We need to indicate which subset corresponds to the features/variables and which column corresponds to the class we are trying to predict. \n",
    "# Finally, we also indicate the percentage of the dataset to include into the train split (proportion of samples used to train the model)\n",
    "train_x, test_x, train_y, test_y = train_test_split(features,label,train_size=0.7,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do some \"sanity checks\"\n",
    "\n",
    "# Compute number of samples in training\n",
    "\n",
    "# Compute number of samples in test\n",
    "\n",
    "# Compute total number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest classifier\n",
    "\n",
    "### Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Random Forest parameters\n",
    "n_estimators=30\n",
    "criterion='gini'\n",
    "max_depth=30\n",
    "min_samples_split=5\n",
    "min_samples_leaf=5\n",
    "max_features='auto'\n",
    "max_leaf_nodes=None\n",
    "bootstrap=True\n",
    "oob_score=True\n",
    "n_jobs=1\n",
    "random_state=None\n",
    "verbose=0\n",
    "class_weight='balanced'\n",
    "\n",
    "# build the Random Forest classifier\n",
    "forest = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth,\n",
    "                             min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
    "                             max_features=max_features, max_leaf_nodes=max_leaf_nodes, bootstrap=bootstrap, oob_score=oob_score,\n",
    "                             n_jobs=n_jobs, random_state=random_state, verbose=verbose,class_weight=class_weight)\n",
    "\n",
    "# train the Random Forest classifier on our dataset\n",
    "RF_classifier = forest.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking the performance of the trained RF classifier on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "mypredtest=RF_classifier.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, mypredtest)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation and graphical representation of the confusion matrix\n",
    "\n",
    "# definition of a helper function (taken from \n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)\n",
    "\n",
    "# get the target labels (it is an output from the classifier)\n",
    "target_names=RF_classifier.classes_\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(test_y, mypredtest)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the best predictors of the cancer class (benign=2/malign=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "\n",
    "importances=RF_classifier.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Get the name of each features\n",
    "feature_list=np.array(features.columns[0:9])\n",
    "\n",
    "# Visualize\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(train_x.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(train_x.shape[1]), feature_list[indices],rotation=45,horizontalalignment='right')\n",
    "plt.xlim([-1, train_x.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try on another dataset and adjust the parametrization of Random Forest classifier and the sampling size of training and testing data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
